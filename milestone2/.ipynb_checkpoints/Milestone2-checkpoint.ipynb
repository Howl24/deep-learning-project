{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2 - CS109B Project Group 29\n",
    "**\"Predicting Movie Genres\"**<br>\n",
    "**CS109B (Spring 2017) Final Project Group 29**<br>\n",
    "Calvin J Chiew, Tim Hagmann, Ji Hua<br>\n",
    "TF: Rashmi Banthia<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "\n",
    "- Discussion about the imbalanced nature of the data and how you want to address it\n",
    "- Description of your data\n",
    "- What does your choice of Y look like?\n",
    "- Which features do you choose for X and why?\n",
    "- How do you sample your data, how many samples, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib import urlopen\n",
    "import threading\n",
    "from threading import Timer\n",
    "from time import time, sleep\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we used the TMDb API to scrape information on movies that have `tmdb_id` of 1 through 160,000. About 60,000 of these `tmdb_id`'s were empty, returning about 100,000 actual records.\n",
    "\n",
    "Given that `tmdb_id`'s are not assigned in chronological order or in any particular pattern, this 100,000 movies represent a **random** sample of all movies listed on TMDb (estimated to be around 300,000). We chose 100,000 as we believe it is a sufficiently large sample size to develop our traditional ML and deep learning models.\n",
    "\n",
    "We dropped about 30,000 records that were missing poster paths and `imdb_id`'s, leaving us with about 70,000 movies. Finally, we extracted the additional metadata we wanted for these movies from IMDb and matched them to the TMDb records based on `imdb_id`.\n",
    "\n",
    "You can view the raw data file we gathered on our GitHub repository here: https://github.com/greenore/deep-learning-project/tree/master/milestone2/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome Variable (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome variable is the movie genre, which is classified into 19 categories by TMDb (namely Adventure, Fantasy, Animation, Drama, Horror, Action, Comedy, History, Western, Thriller, Crime, Documentary, Science Fiction, Mystery, Music, Romance, Family, War and Foreign). We decided against regrouping the genres because even if we had chosen to do so, we would have only collapsed a few groups (eg. Action-Adventure, Thriller-Crime-Mystery) based on our genre pair analysis in earlier EDA (see Milestone 1). We did not feel that this small reduction in genre categories would make a significant difference in the larger picture. To simplify the problem, we will also not use the genre classifications on IMDb.\n",
    "\n",
    "In addition, each movie may fall into multiple genres, ie. this is a multi-label problem. To address this issue, we coded the outcome into 19 columns of binary (1/0) flags, one for each of the 19 TMDb genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor Variables (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two sets of data, one with movie posters as features, and the other with movie metadata. For the former, we downloaded w500 resolution movie posters from TMDb. For the latter, we have chosen to include the following features:\n",
    "\n",
    "*Extracted from TMDb*\n",
    "- Title\n",
    "- Plot summary\n",
    "- Production company\n",
    "- Release date\n",
    "- Runtime (mins)\n",
    "- Budget (USD)\n",
    "- Revenue (USD)\n",
    "- Popularity (on scale of ??)\n",
    "- Average user rating (on scale of 1-10)\n",
    "\n",
    "*Extracted from IMDb*\n",
    "- Producer (first name listed)\n",
    "- Director (first name listed)\n",
    "- Writer (first name listed)\n",
    "- Cast (first 4 names listed)\n",
    "- Country of origin / language\n",
    "- Picture rating (US MPAA categories eg. PG-13, R-21)\n",
    "\n",
    "These features were chosen based on our prior beliefs about what are potential predictors of movie genre (see Milestone 1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words Analysis (for Title & Plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we use bag-of-words analysis to convert the title and plot summaries into features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmdb_id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title_plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0094675</td>\n",
       "      <td>Ariel Taisto Kasurinen is a Finnish coal miner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0092149</td>\n",
       "      <td>Shadows in Paradise An episode in the life of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0113101</td>\n",
       "      <td>Four Rooms It's Ted the Bellhop's first night ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0107286</td>\n",
       "      <td>Judgment Night While racing to a boxing match,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0825671</td>\n",
       "      <td>Life in Loops (A Megacities RMX) Timo Novotny ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tmdb_id  imdb_id                                         title_plot\n",
       "0       2  0094675  Ariel Taisto Kasurinen is a Finnish coal miner...\n",
       "1       3  0092149  Shadows in Paradise An episode in the life of ...\n",
       "2       5  0113101  Four Rooms It's Ted the Bellhop's first night ...\n",
       "3       6  0107286  Judgment Night While racing to a boxing match,...\n",
       "4       8  0825671  Life in Loops (A Megacities RMX) Timo Novotny ..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv file\n",
    "raw = pd.read_table('tmdb_movie_info_100k.txt')\n",
    "\n",
    "# concatenate title and plot together \n",
    "raw['title_plot'] = raw['title'].astype(str) + ' ' + raw['plot'].astype(str)\n",
    "\n",
    "# drop all columns except title and plot\n",
    "raw = raw[['tmdb_id', 'imdb_id', 'title_plot']]\n",
    "\n",
    "# view first few rows\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create bag-of-words matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# ignore stop words and only consider words that make up at least 1% of the corpus\n",
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=0.01)\n",
    "corpus = raw['title_plot'].values\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'accident', u'action', u'adventure', u'affair', u'age', u'agent', u'america', u'american', u'amp', u'army', u'arrives', u'art', u'artist', u'attempt', u'attempts', u'away', u'baby', u'bad', u'band', u'based', u'battle', u'beautiful', u'begin', u'begins', u'best', u'big', u'black', u'blood', u'body', u'book', u'boss', u'boy', u'boyfriend', u'boys', u'break', u'bring', u'brings', u'british', u'brother', u'brothers', u'business', u'called', u'car', u'career', u'case', u'caught', u'century', u'chance', u'change', u'characters', u'child', u'childhood', u'children', u'city', u'class', u'classic', u'close', u'college', u'come', u'comedy', u'comes', u'coming', u'company', u'concert', u'control', u'cop', u'country', u'couple', u'course', u'crew', u'crime', u'criminal', u'dangerous', u'dark', u'daughter', u'david', u'day', u'days', u'dead', u'deadly', u'deal', u'death', u'decide', u'decides', u'despite', u'detective', u'die', u'dies', u'different', u'directed', u'director', u'discover', u'discovers', u'doctor', u'documentary', u'does', u'doesn', u'don', u'dr', u'drama', u'dream', u'dreams', u'drug', u'early', u'earth', u'end', u'ends', u'escape', u'events', u'eventually', u'evil', u'ex', u'face', u'fall', u'falls', u'family', u'famous', u'far', u'father', u'female', u'fight', u'film', u'films', u'final', u'finally', u'finds', u'following', u'follows', u'footage', u'force', u'forced', u'forces', u'form', u'free', u'french', u'friend', u'friends', u'friendship', u'future', u'game', u'gang', u'german', u'gets', u'getting', u'girl', u'girlfriend', u'girls', u'gives', u'goes', u'going', u'good', u'government', u'great', u'group', u'guy', u'hand', u'hands', u'happy', u'hard', u'having', u'head', u'heart', u'help', u'hero', u'high', u'history', u'hit', u'home', u'horror', u'house', u'human', u'husband', u'ii', u'including', u'inside', u'instead', u'involved', u'island', u'japanese', u'job', u'john', u'join', u'journey', u'just', u'kids', u'kill', u'killed', u'killer', u'killing', u'king', u'know', u'known', u'la', u'lady', u'land', u'late', u'later', u'law', u'lead', u'leader', u'leads', u'learn', u'learns', u'leave', u'leaves', u'left', u'life', u'like', u'little', u'live', u'lives', u'living', u'local', u'london', u'long', u'look', u'looking', u'los', u'lost', u'love', u'lover', u'make', u'makes', u'making', u'man', u'marriage', u'married', u'marry', u'master', u'meet', u'meets', u'members', u'men', u'middle', u'military', u'mind', u'missing', u'mission', u'modern', u'money', u'mother', u'moves', u'movie', u'mr', u'murder', u'murdered', u'music', u'mysterious', u'named', u'nan', u'new', u'night', u'novel', u'officer', u'old', u'order', u'overview', u'owner', u'parents', u'paris', u'party', u'past', u'people', u'perfect', u'personal', u'place', u'plan', u'plans', u'play', u'plays', u'plot', u'police', u'political', u'popular', u'power', u'powerful', u'prison', u'private', u'problems', u'quickly', u'race', u'real', u'really', u'red', u'relationship', u'released', u'rescue', u'return', u'returns', u'revenge', u'rich', u'right', u'road', u'rock', u'romance', u'romantic', u'run', u'runs', u'save', u'school', u'search', u'second', u'secret', u'seen', u'sees', u'self', u'sent', u'series', u'set', u'sets', u'sex', u'sexual', u'short', u'shot', u'shows', u'singer', u'sister', u'small', u'society', u'son', u'soon', u'south', u'special', u'stage', u'stand', u'star', u'stars', u'start', u'starts', u'state', u'stay', u'stop', u'stories', u'story', u'strange', u'street', u'student', u'students', u'successful', u'suddenly', u'summer', u'taken', u'takes', u'taking', u'tale', u'teacher', u'team', u'tells', u'things', u'time', u'tour', u'town', u'tries', u'trip', u'trouble', u'true', u'truth', u'try', u'trying', u'turn', u'turns', u'tv', u'use', u'using', u'video', u'village', u'visit', u'want', u'wants', u'war', u'way', u'wealthy', u'west', u'white', u'wife', u'wild', u'win', u'woman', u'women', u'work', u'working', u'works', u'world', u'writer', u'written', u'year', u'years', u'york', u'young']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 389 words in the vocabulary, as shown above. We view the final weighted frequency matrix which was generated using Term Frequency times Inverse Document Frequency (tf-idf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_accident</th>\n",
       "      <th>word_action</th>\n",
       "      <th>word_adventure</th>\n",
       "      <th>word_affair</th>\n",
       "      <th>word_age</th>\n",
       "      <th>word_agent</th>\n",
       "      <th>word_america</th>\n",
       "      <th>word_american</th>\n",
       "      <th>word_amp</th>\n",
       "      <th>word_army</th>\n",
       "      <th>...</th>\n",
       "      <th>word_work</th>\n",
       "      <th>word_working</th>\n",
       "      <th>word_works</th>\n",
       "      <th>word_world</th>\n",
       "      <th>word_writer</th>\n",
       "      <th>word_written</th>\n",
       "      <th>word_year</th>\n",
       "      <th>word_years</th>\n",
       "      <th>word_york</th>\n",
       "      <th>word_young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.665059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165786</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 389 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_accident  word_action  word_adventure  word_affair  word_age  \\\n",
       "0            0.0          0.0        0.000000     0.000000       0.0   \n",
       "1            0.0          0.0        0.000000     0.665059       0.0   \n",
       "2            0.0          0.0        0.000000     0.000000       0.0   \n",
       "3            0.0          0.0        0.000000     0.000000       0.0   \n",
       "4            0.0          0.0        0.184482     0.000000       0.0   \n",
       "\n",
       "   word_agent  word_america  word_american  word_amp  word_army     ...      \\\n",
       "0         0.0           0.0            0.0  0.000000        0.0     ...       \n",
       "1         0.0           0.0            0.0  0.000000        0.0     ...       \n",
       "2         0.0           0.0            0.0  0.000000        0.0     ...       \n",
       "3         0.0           0.0            0.0  0.394097        0.0     ...       \n",
       "4         0.0           0.0            0.0  0.000000        0.0     ...       \n",
       "\n",
       "   word_work  word_working  word_works  word_world  word_writer  word_written  \\\n",
       "0        0.0           0.0         0.0    0.000000          0.0      0.000000   \n",
       "1        0.0           0.0         0.0    0.000000          0.0      0.000000   \n",
       "2        0.0           0.0         0.0    0.000000          0.0      0.000000   \n",
       "3        0.0           0.0         0.0    0.000000          0.0      0.000000   \n",
       "4        0.0           0.0         0.0    0.119018          0.0      0.180166   \n",
       "\n",
       "   word_year  word_years  word_york  word_young  \n",
       "0        0.0         0.0   0.000000         0.0  \n",
       "1        0.0         0.0   0.000000         0.0  \n",
       "2        0.0         0.0   0.000000         0.0  \n",
       "3        0.0         0.0   0.000000         0.0  \n",
       "4        0.0         0.0   0.165786         0.0  \n",
       "\n",
       "[5 rows x 389 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagofwords = pd.DataFrame(X.toarray(), columns=vocab)\n",
    "bagofwords = bagofwords.add_prefix('word_')\n",
    "bagofwords.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Posters to Features and Further Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Tim to assist with this section)\n",
    "- convert posters to pixel features\n",
    "- ?apply PCA, get top PCs\n",
    "- further cleanup/data manipulation eg. production companies, release date (apply R scripts)\n",
    "- get dummy variables for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Coding Environment\n",
    "The analysis was performed using a R-Kernel. In order to reproduce the results, the kernel has to be switched. To install the R essentials in the current environment, execute the following code in your system prompt:\n",
    "\n",
    "```bash\n",
    "conda install -c r r-essentials\n",
    "```\n",
    "\n",
    "**Machine:**   Windows 7 | Intel i7-3540M @ 3.00GHz | 16.00 GB RAM\n",
    "\n",
    "**R Version:** Microsoft R Open 3.3.2 -- \"Sincere Pumpkin Patch\"\n",
    "\n",
    "We need to set some global options for the R environment. The only thing that one might have to change is the .libPaths part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'C'"
      ],
      "text/latex": [
       "'C'"
      ],
      "text/markdown": [
       "'C'"
      ],
      "text/plain": [
       "[1] \"C\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Options\n",
    "options(scipen=10)\n",
    "update_package <- FALSE\n",
    "options(java.parameters=\"-Xmx6g\")\n",
    "options(warn=-1)\n",
    "\n",
    "# Set the library/packages path\n",
    "options(repos = c(CRAN = \"https://cran.revolutionanalytics.com\"))\n",
    ".libPaths(\"C:/Local/R/win-library/3.2\")\n",
    "\n",
    "# Set local time\n",
    "Sys.setenv(LANG = \"en\")\n",
    "Sys.setlocale(\"LC_TIME\", \"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we load some project specific packages and functions. `01_init.R` is just a helper script, `02_packages.R` loads and installs the required packages and libraries, and `03_functions.R` loads functions specifically written for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Init files (always execute, eta: 10s)\n",
    "suppressMessages(source(\"scripts/01_init.R\"))                   # Helper functions to load packages\n",
    "suppressMessages(source(\"scripts/02_packages.R\"))               # Load all necessary packages\n",
    "suppressMessages(source(\"scripts/03_functions.R\"))              # Load project specific functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Data\n",
    "First, we load the data gathered from TMDb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Final Dataframe\n",
    "\n",
    "Finally, we take a look at the final dataframe, which has a total of () observations and () variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we visualize the imbalanced nature of our data by plotting the number of movies in each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ggplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can see that there is imbalanced data, as there are a lot more () movies than () movies. To address this issue, we will employ **class weighting** in our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we assess the amount of missing data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate table to assess extent of missing data\n",
    "def missing_values_table(df): \n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum()/len(df)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(columns = {0: 'Missing Values', 1: '% Missing Values'})\n",
    "    return mis_val_table_ren_columns\n",
    "\n",
    "missing_values_table(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Moving forward, we will split the dataset into training and testing sets. Then, we will train classification models with traditional machine learning methods, such as random forest and support vector machine, and evaluate their performance on the test set. We will consider and explain what we want to use as our performance metric(s). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
